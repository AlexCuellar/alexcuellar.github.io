---
layout: post
title: Fair Contextual Bandit Algorithm
category:
  - Projects
tags:
  - Machine Learning
  - Algorithms
---

## Overview
In the summer of 2019, after my Sophomore year, I worked as an undergraduate researcher with the University of Souther California REU (Reserach Experiences for Undergraduates) program.  During this time, I worked under Prof. Stefanos Nikolaidis at the ICAROS (Interactive and Calaborative Autonomous Robotic Systems Lab) to develop the the first fair online contextual bandit algorithm for use in human-robot or human-computer interaction.  So what exacly is a fair online contectual bandit algorithm? Bandit algorithms are a fundamental class of reinforcement learning algorithms which learn the optimal action to take given a set of \\n finite options for an action.  For example, imagine a customer service robot needs to refer customers to an employee to solve a problem, which employee is the best choice to maximize the score that customers give in a feedback survey.  <!--more-->
As an extension, I split the stem into four parts and dipped each into a different colored solution. Here are the results:

<div class="center">
    <img src="/assets/img/carnation/carnation1.jpg" alt="Initial carnation setup" class="three-image-row">
    <img src="/assets/img/carnation/carnation2.jpg" alt="Resulting carnation" class="three-image-row">
</div>
*Carnation setup (left). Results after 4 days (right).*
